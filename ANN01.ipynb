{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNGi9CKJg7DX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('diabetes.csv')"
      ],
      "metadata": {
        "id": "7kK100BwhsS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X = data.drop('Outcome', axis=1).values\n",
        "y = data['Outcome'].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "-DoFsMIXhdMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_idx = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_idx], y[:train_idx]\n",
        "X_test, y_test = X[train_idx:], y[train_idx:]"
      ],
      "metadata": {
        "id": "pN5YTFYyhm8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)"
      ],
      "metadata": {
        "id": "NeCPL7kXsE2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ANN architecture\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 10\n",
        "output_dim = 1\n",
        "W1 = np.random.randn(input_dim, hidden_dim)\n",
        "b1 = np.zeros(hidden_dim)\n",
        "W2 = np.random.randn(hidden_dim, output_dim)\n",
        "b2 = np.zeros(output_dim)"
      ],
      "metadata": {
        "id": "ei-JJpqWiR7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.01, 0.001, 0.0001]\n",
        "epochs = [50, 100, 200]\n",
        "batch_sizes = [16, 32, 64]"
      ],
      "metadata": {
        "id": "4pEUak0ZiVTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Loop through all hyperparameters combinations\n",
        "for lr in learning_rates:\n",
        "    for e in epochs:\n",
        "        for bs in batch_sizes:\n",
        "            # Define the activation function (sigmoid)\n",
        "            def sigmoid(x):\n",
        "                return 1 / (1 + np.exp(-x))\n",
        "\n",
        "            # Define the forward propagation function\n",
        "            def forward(X, W1, b1, W2, b2):\n",
        "                h = sigmoid(np.dot(X, W1) + b1)\n",
        "                y_hat = sigmoid(np.dot(h, W2) + b2)\n",
        "                return h, y_hat\n",
        "\n",
        "            # Define the backward propagation function\n",
        "            def backward(X, y, h, y_hat, W2, batch_size):\n",
        "                error = y_hat - y.reshape(-1, 1)\n",
        "                dW2 = np.dot(h.T, error) / batch_size\n",
        "                db2 = np.sum(error, axis=0) / batch_size\n",
        "                dh = np.dot(error, W2.T) * h * (1 - h)\n",
        "                dW1 = np.dot(X.T, dh) / batch_size\n",
        "                db1 = np.sum(dh, axis=0) / batch_size\n",
        "                return dW1, db1, dW2, db2\n",
        "\n",
        "            # Train the network\n",
        "            for i in range(e):\n",
        "                for j in range(0, X_train.shape[0], bs):\n",
        "                    X_batch = X_train[j:j+bs]\n",
        "                    y_batch = y_train[j:j+bs]\n",
        "                    h, y_hat = forward(X_batch, W1, b1, W2, b2)\n",
        "                    dW1, db1, dW2, db2 = backward(X_batch, y_batch, h, y_hat, W2, bs)\n",
        "                    W1 -= lr * dW1\n",
        "                    b1 -= lr * db1\n",
        "                    W2 -= lr * dW2\n",
        "                    b2 -= lr * db2\n",
        "\n",
        "            # Test the network\n",
        "            h, y_hat = forward(X_test, W1, b1, W2, b2)\n",
        "            y_pred = np.round(y_hat)\n",
        "            accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "            # Save the best hyperparameters\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_params = {'lr': lr, 'epochs': e, 'batch_size': bs}\n",
        "\n",
        "print(\"Best hyperparameters: \", best_params)\n",
        "print(\"Best accuracy: \", best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVeSfz92iuBB",
        "outputId": "6b4d6550-51e3-41ce-c37a-9fa6a3a91aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'lr': 0.01, 'epochs': 100, 'batch_size': 16}\n",
            "Best accuracy:  0.7532467532467533\n"
          ]
        }
      ]
    }
  ]
}